import os
import yaml
import random
import shutil
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from torchvision.utils import save_image
from ultralytics import YOLO

# ç¡®ä¿ç¯å¢ƒå˜é‡ä¸ä¼šå½±å“æ€§èƒ½
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["OPENBLAS_NUM_THREADS"] = "1"

# é…ç½®å‚æ•°
CONFIG = {
    "data_dir": "Datasets",
    "image_dir": "images",
    "label_dir": "labels",
    "split_ratio": [0.7, 0.2, 0.1],
    "model_type": "yolov8n-pose.pt",
    "epochs": 200,
    "imgsz": 640,
    "batch": 32,
    "device": "0",
    "workers": 0,  # é¿å… dataloader çº¿ç¨‹é—®é¢˜
    "seed": 42
}

# åˆ›å»ºç›®å½•
os.makedirs("models", exist_ok=True)
os.makedirs("results", exist_ok=True)


def plot_training_curves(model):
    """ ç»˜åˆ¶æŸå¤±æ›²çº¿ã€mAP æ›²çº¿ç­‰è®­ç»ƒæŒ‡æ ‡ """
    try:
        csv_file = next((f for f in os.listdir(model.trainer.save_dir) if f.endswith(".csv")), None)
        if not csv_file:
            print("âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒæ—¥å¿— CSV æ–‡ä»¶ï¼Œè·³è¿‡ç»˜å›¾")
            return

        metrics = pd.read_csv(os.path.join(model.trainer.save_dir, csv_file))

        plt.figure(figsize=(12, 8))

        # 1. æŸå¤±æ›²çº¿
        plt.subplot(2, 2, 1)
        for col in [c for c in metrics.columns if 'loss' in c]:
            plt.plot(metrics["epoch"], metrics[col], label=col.split('/')[-1])
        plt.title("Training Loss")
        plt.legend()

        # 2. mAP å˜åŒ–æ›²çº¿
        plt.subplot(2, 2, 2)
        for col in [c for c in metrics.columns if 'metrics/mAP' in c]:
            plt.plot(metrics["epoch"], metrics[col], label=col.split('/')[-1])
        plt.title("Validation mAP")
        plt.legend()

        # 3. å­¦ä¹ ç‡å˜åŒ–æ›²çº¿
        plt.subplot(2, 2, 3)
        if 'lr/pg0' in metrics.columns:
            plt.plot(metrics["epoch"], metrics["lr/pg0"], label='Learning Rate')
        plt.title("Learning Rate Schedule")
        plt.legend()

        plt.tight_layout()
        plt.savefig("results/training_curves.png", dpi=300)
        plt.close()
    except Exception as e:
        print(f"âš ï¸ ç»˜åˆ¶è®­ç»ƒæ›²çº¿æ—¶å‡ºé”™: {str(e)}")


def analyze_results(model):
    """é²æ£’æ€§æ›´å¼ºçš„ç»“æœåˆ†æå‡½æ•°"""
    try:
        val_results = model.val(split="val")
        os.makedirs("results", exist_ok=True)

        # åˆå§‹åŒ–å˜é‡
        px, py, ap = None, None, None

        if hasattr(val_results, 'box'):
            box = val_results.box

            # å®‰å…¨è·å–æŒ‡æ ‡æ•°æ®
            py = getattr(box, 'p', None)
            if py is None:
                py = getattr(box, 'precisions', [0.5])  # å…¼å®¹ä¸åŒç‰ˆæœ¬

            # ç¡®ä¿pyæ˜¯å¯è¿­ä»£å¯¹è±¡
            if not isinstance(py, (list, np.ndarray)):
                py = [float(py)] if py else [0.5]

            py = np.array(py).flatten()  # å¼ºåˆ¶è½¬ä¸º1Dæ•°ç»„

            # ç”Ÿæˆå¯¹åº”xè½´
            px = np.linspace(0, 1, len(py)) if len(py) > 1 else np.array([0, 1])

            # è·å–APå€¼ï¼ˆå…¼å®¹ä¸åŒæ ¼å¼ï¼‰
            ap = getattr(box, 'ap', None)
            if ap is None:
                ap = getattr(box, 'ap50', 0.0)
            ap_value = float(ap[0] if isinstance(ap, (list, np.ndarray)) else ap)

            # ç»˜åˆ¶PRæ›²çº¿
            plt.figure(figsize=(9, 6))
            if len(py) == 1:  # å•ç‚¹æƒ…å†µ
                plt.scatter(0.5, py[0], s=100, c='blue',
                            label=f'mAP@0.5: {ap_value:.3f}')
            else:
                plt.plot(px, py, 'b-', linewidth=3,
                         label=f'mAP@0.5: {ap_value:.3f}')

            plt.xlabel('Recall')
            plt.ylabel('Precision')
            plt.xlim(0, 1)
            plt.ylim(0, 1)
            plt.title('Precision-Recall Curve')
            plt.legend()
            plt.show()
            plt.savefig("results/pr_curve.png", dpi=300, bbox_inches='tight')
            plt.close()
            print("âœ… PRæ›²çº¿å·²ä¿å­˜åˆ° results/pr_curve.png")

    except Exception as e:
        print(f"âš ï¸ ç»“æœåˆ†æå‡ºé”™: {str(e)}")
        # å®‰å…¨æ‰“å°è°ƒè¯•ä¿¡æ¯
        debug_info = {
            'px': px.shape if hasattr(px, 'shape') else str(px),
            'py': py.shape if hasattr(py, 'shape') else str(py),
            'ap': str(ap)
        }
        print(f"ğŸ è°ƒè¯•ä¿¡æ¯: {debug_info}")


def train_model():
    """ è®­ç»ƒæ¨¡å‹å¹¶ä¿å­˜åˆ° models ç›®å½• """
    model = YOLO(CONFIG["model_type"])

    results = model.train(
        data=f"{CONFIG['data_dir']}/data.yaml",
        epochs=CONFIG["epochs"],
        imgsz=CONFIG["imgsz"],
        batch=CONFIG["batch"],
        device=CONFIG["device"],
        save=True,
        save_period=10,
        exist_ok=True,
        workers=CONFIG["workers"],
        save_dir="models",
        fliplr = 0,  # 50% æ¦‚ç‡æ°´å¹³ç¿»è½¬
        flipud = 0,  # 20% æ¦‚ç‡å‚ç›´ç¿»è½¬
        degrees = 180 # å…è®¸Â±10Â° æ—‹è½¬
    )

    best_model_path = os.path.join("models", "best.pt")
    last_model_path = os.path.join("models", "last.pt")

    if os.path.exists(best_model_path):
        shutil.move(best_model_path, "models/best.pt")
    if os.path.exists(last_model_path):
        shutil.move(last_model_path, "models/last.pt")

    return model


def test_model(model):
    """ åœ¨æµ‹è¯•é›†ä¸Šæ¨ç†ï¼Œå¹¶ä¿å­˜ç»“æœ """
    print("\nğŸ” åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œæ¨ç†...")
    results = model.predict(
        source=f"{CONFIG['data_dir']}/test/images",
        save=True,
        project="results",
        name="test_predictions"
    )
    print("âœ… æ¨ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ° results/test_predictions")


def save_augmented_samples(model, num_samples=5):
    """ ä» dataloader ç›´æ¥è·å–å¢å¼ºåçš„è®­ç»ƒæ•°æ®ï¼Œå¹¶ä¿å­˜ """
    print("\nğŸ“· æ­£åœ¨ä¿å­˜è®­ç»ƒæ—¶çš„æ•°æ®å¢å¼ºæ ·æœ¬...")

    # è·å–è®­ç»ƒæ—¶çš„æ•°æ®åŠ è½½å™¨
    dataloader = model.trainer.get_dataloader('./Datasets/train/images')  # ç›´æ¥è®¿é—® dataloader
    os.makedirs("results/augmentations/train", exist_ok=True)

    # éå†æ•°æ®é›†ï¼Œæå–å¢å¼ºåçš„æ ·æœ¬
    for i, (images, labels) in enumerate(dataloader):
        if i >= num_samples:  # åªä¿å­˜æŒ‡å®šæ•°é‡çš„æ ·æœ¬
            break
        save_path = f"results/augmentations/train/sample_{i}.png"

        # ä¿å­˜ PyTorch å¼ é‡æ ¼å¼çš„å¢å¼ºå›¾ç‰‡
        save_image(images / 255.0, save_path)  # å½’ä¸€åŒ–åˆ° [0,1]ï¼Œé¿å…é¢œè‰²é”™è¯¯

    print(f"âœ… æ•°æ®å¢å¼ºæ ·æœ¬å·²ä¿å­˜è‡³ 'results/augmentations/train'")


def save_augmentation_samples(model, output_dir="aug_samples"):
    """
    ä¿å­˜è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¢å¼ºæ ·æœ¬
    :param model: è®­ç»ƒå¥½çš„YOLOæ¨¡å‹
    :param output_dir: è¾“å‡ºç›®å½•
    """
    os.makedirs(output_dir, exist_ok=True)

    # ä»è®­ç»ƒæ—¥å¿—ä¸­æå–å¢å¼ºæ ·æœ¬
    train_log_dir = model.trainer.save_dir
    mosaic_files = []

    # æŸ¥æ‰¾æ‰€æœ‰å¢å¼ºæ ·æœ¬å›¾ç‰‡
    for root, _, files in os.walk(train_log_dir):
        for f in files:
            if f.startswith("train_batch") and f.endswith(".jpg"):
                mosaic_files.append(os.path.join(root, f))

    # å¤åˆ¶æœ€æ–°çš„10å¼ å¢å¼ºæ ·æœ¬
    for i, src in enumerate(sorted(mosaic_files)[-10:]):
        dst = os.path.join(output_dir, f"aug_sample_{i + 1}.jpg")
        shutil.copy(src, dst)

    # å¦‚æœæ²¡æœ‰è‡ªåŠ¨ä¿å­˜çš„æ ·æœ¬ï¼Œæ‰‹åŠ¨ç”Ÿæˆ
    if len(mosaic_files) == 0:
        print("\nè­¦å‘Šï¼šæœªæ‰¾åˆ°è‡ªåŠ¨ä¿å­˜çš„å¢å¼ºæ ·æœ¬ï¼Œå°†æ‰‹åŠ¨ç”Ÿæˆ...")
        from ultralytics.data.augment import Albumentations
        from PIL import Image

        # ç¤ºä¾‹å¢å¼ºç®¡é“
        augmenter = Albumentations(
            augment=True,
            hsv_h=0.015,  # è‰²è°ƒå¢å¼º
            hsv_s=0.7,  # é¥±å’Œåº¦å¢å¼º
            hsv_v=0.4,  # æ˜åº¦å¢å¼º
            degrees=10,  # æ—‹è½¬è§’åº¦
            translate=0.1,  # å¹³ç§»
            scale=0.5,  # ç¼©æ”¾
            shear=2  # å‰ªåˆ‡
        )

        # éšæœºé€‰æ‹©è®­ç»ƒé›†å›¾ç‰‡æ¼”ç¤º
        img_files = [f for f in os.listdir("yolo_dataset/train/images")
                     if f.endswith(('.jpg', '.png'))][:5]

        for i, img_file in enumerate(img_files):
            img = Image.open(os.path.join("yolo_dataset/train/images", img_file))

            # åº”ç”¨å¢å¼º
            augmented = augmenter(image=np.array(img))['image']

            # ä¿å­˜å¯¹æ¯”å›¾
            fig, ax = plt.subplots(1, 2, figsize=(12, 6))
            ax[0].imshow(img)
            ax[0].set_title("Original")
            ax[0].axis('off')

            ax[1].imshow(augmented)
            ax[1].set_title("Augmented")
            ax[1].axis('off')

            plt.show()
            plt.savefig(os.path.join(output_dir, f"aug_compare_{i + 1}.jpg"),
                        dpi=150, bbox_inches='tight')
            plt.close()

    print(f"\nå¢å¼ºæ ·æœ¬å·²ä¿å­˜åˆ°: {os.path.abspath(output_dir)}")

def visualize_augmentations(model):
    """
    1. æ­£ç¡®è·å–è®­ç»ƒæ—¶çš„å¢å¼ºæ•°æ®
    2. ä»…ç”¨äºå¯è§†åŒ–ï¼Œä¸è¿›è¡Œæ¨ç†
    """
    save_augmented_samples(model, num_samples=5)


if __name__ == "__main__":
    random.seed(CONFIG["seed"])
    np.random.seed(CONFIG["seed"])

    print("ğŸš€ å¼€å§‹è®­ç»ƒ YOLOv8 ...")
    model = train_model()

    print("\nğŸ“Š è¯„ä¼°è®­ç»ƒç»“æœ...")
    analyze_results(model)

    print("\nğŸ¯ ç»˜åˆ¶è®­ç»ƒæ›²çº¿...")
    plot_training_curves(model)

    print("\nğŸ›  è¿è¡Œæµ‹è¯•é›†æ¨ç†...")
    test_model(model)

    print("\nğŸ” å¯è§†åŒ–è®­ç»ƒæ•°æ®å¢å¼º...")
    # visualize_augmentations(model)

    save_augmentation_samples(model)


    print("\nâœ… è®­ç»ƒå®Œæˆï¼")
